{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Review Sentiment Prediction\n",
    "## By Bharath Varma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ground Truth:\n",
    "    The Ground truth is found using website http://text-processing.com/demo/sentiment/.\n",
    "    Assuming that the reviews written by a Human or any NLP approach would not be perfect and biased, We've used the above source to get the ground truth by using R script, when submitted, the review gets the class.\n",
    "    \n",
    "Sentiment to the reviews from the above are Positive, Negative and Neutral."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assumption: A Neutral rating doesn't mean that the movie is negative. Having this said, Neutral rating doesn't stop people watching the movie. So, We've converted the Neutral reviews to Positive. And the code ML based predictions follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies/Packages/modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import Dependecies/packages/modules\n",
    "import csv\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# File contains two columns: Class, Review Text\n",
    "# first column is the assigned sentiment (positive or negative)\n",
    "# second column is the review text content\n",
    "def load_file():\n",
    "    with open('Movie_Review1.csv') as csv_file:\n",
    "        reader = csv.reader(csv_file,delimiter=\",\")\n",
    "        reader.next()\n",
    "        data =[]\n",
    "        target = []\n",
    "        for row in reader:\n",
    "            # skip missing data\n",
    "            if row[0] and row[1]:\n",
    "                data.append(row[0])\n",
    "                target.append(row[1])\n",
    "\n",
    "        return data,target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# preprocess creates the term frequency matrix for the review data set\n",
    "def preprocess():\n",
    "    data,target = load_file()\n",
    "    count_vectorizer = CountVectorizer(binary='true',stop_words='english',lowercase='true')\n",
    "    data = count_vectorizer.fit_transform(data)\n",
    "    #tfidf_data = TfidfTransformer(use_idf=False).fit_transform(data)\n",
    "    #svd = TruncatedSVD(algorithm='randomized', n_components=100,random_state=43, tol=0.0)\n",
    "    #data = svd.fit(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We've used an ensemble technique, Random Forest, to generalise the model and to escape bias.\n",
    " Other Models like Logistic regression, SVM could predict with accuracies closer to 68/70."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def learn_model(data,target):\n",
    "    # preparing data for split validation. 70% training, 30% test\n",
    "    data_train,data_test,target_train,target_test = cross_validation.train_test_split(data,target,\n",
    "                                                                                      test_size=0.3,\n",
    "                                                                                      random_state=43)\n",
    "    # Random Forests\n",
    "    params = {'max_depth':12,'min_samples_split':3,\n",
    "              'n_jobs':1, \n",
    "              'n_estimators': 700,\n",
    "              'class_weight':'balanced_subsample'}\n",
    "    forest = RandomForestClassifier(**params)\n",
    "    classifier = forest.fit(data_train,target_train)\n",
    "    \n",
    "    predicted = classifier.predict(data_test)\n",
    "    evaluate_model(target_test,predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read more about model evaluation metrics here\n",
    "# http://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "def evaluate_model(target_true,target_predicted):\n",
    "    print classification_report(target_true,target_predicted)\n",
    "    print \"The accuracy score is {:.2%}\".format(accuracy_score(target_true,target_predicted))\n",
    "    print \"The recall score is {:.2%}\".format(recall_score(target_true,target_predicted,pos_label= 'pos', average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    data,target = load_file()\n",
    "    tf_idf = preprocess()\n",
    "    learn_model(tf_idf,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.83      0.73      0.78       269\n",
      "        pos       0.80      0.88      0.84       331\n",
      "\n",
      "avg / total       0.81      0.81      0.81       600\n",
      "\n",
      "The accuracy score is 81.17%\n",
      "The recall score is 87.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.py:976: DeprecationWarning: From version 0.18, binary input will not be handled specially when using averaged precision/recall/F-score. Please use average='binary' to report only the positive class performance.\n",
      "  'positive class performance.', DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
